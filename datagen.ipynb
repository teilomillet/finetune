{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import re\n",
    "from aiohttp import ClientSession\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ.update({\n",
    "    'OPENAI_API_KEY': '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'\n",
    "})\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to read JSONL file and return a list of values for a specific key\n",
    "def read_jsonl(file_path, key):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            json_obj = json.loads(line)\n",
    "            data.append(json_obj[key])\n",
    "    return data\n",
    "\n",
    "def process_generated_prompts(file_path):\n",
    "    prompts = []\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            for prompt_obj in data[\"prompts\"]:\n",
    "                prompts.append(prompt_obj)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON in file: {file_path}\")\n",
    "    return prompts\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "API_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
    "MODEL = os.getenv(\"MODEL_NAME\", \"gpt-3.5-turbo-1106\")\n",
    "MAX_TOKENS = int(os.getenv(\"MAX_TOKENS\", \"3800\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Subject, Concept and Mediums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generation complete. Saved to 'base.json'.\n",
      "1\n",
      "Data generation complete. Saved to 'base.json'.\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def create_prompt(concept, medium, subject):\n",
    "    return (f\"Concept: [{concept}] \"\n",
    "            f\"Subjects to cover in prompt: [{subject}] \"\n",
    "            f\"Subject specific topics: Cover topics that are unique to ways of \"\n",
    "            f\"thinking [{concept}] regarding that specific subject. Prompt must\"\n",
    "            f\"include thinking process, be explicit and have substance.\"\n",
    "            f\"Add persona and context to the prompt to make it subject specific. \"\n",
    "            f\"Explain why the `prompt` is explicitly related to the context.\"\n",
    "            f\"Explain why the `prompt` is tailored for the subject.\"\n",
    "            f\"Explain why the `prompt` is explicitly an instruction about\"\n",
    "            f\"writing/drafting a [{medium}]. \")\n",
    "\n",
    "\n",
    " \n",
    "def create_system_prompt(concept, subject, medium):\n",
    "    return (f\"Write me a diverse list of \"\n",
    "            f\"subject-specific concise prompts or questions or queries that are \"\n",
    "            f\"around [{concept}] in [{subject}].\"\n",
    "            f\"Prompt should contain instructions to write/draft one of these \"\n",
    "            f\"mediums: [{medium}] \"\n",
    "            f'Your response should be JSON in the shape of {{}} '\n",
    "            f'where each prompt has the shape keys for \"subject_specific_topic\"'\n",
    "            f', \"subject\", \"why_prompt_tailored_for_subject\", \"medium_keyword\",'\n",
    "            f'\"why_prompt_concept\", \"why_prompt_contains_instruction_keyword\",'\n",
    "            f'\"prompt\"')\n",
    "\n",
    "def call_openai_api(prompt, system_prompt, model, max_tokens):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "                        model=model, \n",
    "                        response_format={ \"type\": \"json_object\" },\n",
    "                        messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                            ],\n",
    "                        max_tokens=max_tokens)\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error in API call: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_data(concepts, mediums, subjects, output_file, model=\"gpt-3.5-turbo-1106\", max_tokens=3000):\n",
    "     # Randomly select one from each category\n",
    "    concept = random.choice(concepts)\n",
    "    medium = random.choice(mediums)\n",
    "    subject = random.choice(subjects)\n",
    "    \n",
    "    prompt = create_prompt(concept, medium, subject)\n",
    "    system_prompt = create_system_prompt(concept, subject, medium)\n",
    "\n",
    "    json_string = call_openai_api(prompt, system_prompt, model, max_tokens)\n",
    "    if json_string:\n",
    "        with open(output_file, 'a') as f:\n",
    "            f.write(json_string + '\\n')\n",
    "\n",
    "    print(f\"Data generation complete. Saved to '{output_file}'.\")\n",
    "\n",
    "\n",
    "# Paths and data loading\n",
    "concepts = read_jsonl(r'C:\\Users\\eyliw\\code\\finetune\\concepts.jsonl', \"concept\")\n",
    "mediums = read_jsonl(r'C:\\Users\\eyliw\\code\\finetune\\mediums.jsonl', \"medium\")\n",
    "subjects = read_jsonl(r'C:\\Users\\eyliw\\code\\finetune\\subjects.jsonl', \"subject\")\n",
    "\n",
    "\n",
    "# Shuffle lists to add more randomness\n",
    "random.shuffle(concepts)\n",
    "random.shuffle(mediums)\n",
    "random.shuffle(subjects)\n",
    "\n",
    "output_file_path = 'base.json'\n",
    "number_of_prompts_to_generate = 3  # Set the number of prompts you want to generate\n",
    "\n",
    "for _ in range(number_of_prompts_to_generate):\n",
    "    generate_data(concepts, mediums, subjects, output_file_path)\n",
    "    print(f\"{_+1}/{number_of_prompts_to_generate}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGICAL PUZZLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Unable to extract JSON from response: {\n",
      "\"prompt\": \"The following statements each describe a set of five objects arranged in a fixed order. The statements are logically consistent.\\n- In a blockchain conference, there are five cryptocurrencies: Bitcoin, Ethereum, Ripple, Litecoin, and Cardano.\\n- Bitcoin is the oldest cryptocurrency among the five.\\n- Ripple is older than Litecoin.\\n- Ethereum is newer than Ripple.\\n- Cardano is the second-newest cryptocurrency.\n",
      "\n",
      "Q: Given the above statements, which of the following is correct?\n",
      "Options:\n",
      "(A) Bitcoin is the third-oldest.\n",
      "(B) Ethereum is the third-oldest.\n",
      "(C) Ripple is the third-oldest.\n",
      "(D) Litecoin is the third-oldest.\n",
      "(E) Cardano is the third-oldest.\",\n",
      "\"why_prompt_contains_instruction_keyword\": \"The prompt contains the instruction keyword by clearly providing the instructions for creating a logical arrangement puzzle.\",\n",
      "\"why_options_choice\": \"The options present a clear question with multiple-choice answers, allowing the solver to evaluate and choose the correct answer.\"\n",
      "}\n",
      "Error parsing JSON response: Invalid control character at: line 2 column 141 (char 142)\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Error parsing JSON response: Invalid control character at: line 2 column 180 (char 181)\n",
      "Error parsing JSON response: Invalid control character at: line 2 column 155 (char 156)\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-160' coro=<main() done, defined at C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\650518064.py:85> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\650518064.py\", line 90, in main\n",
      "    await asyncio.gather(*tasks)\n",
      "  File \"C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\650518064.py\", line 53, in generate_data\n",
      "    response = await call_openai_api(prompt, system_prompt, model, max_tokens)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\650518064.py\", line 41, in call_openai_api\n",
      "    async with session.post(API_ENDPOINT, headers=headers, json=payload) as response:\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 894, in start\n",
      "    with self._timer:\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\helpers.py\", line 721, in __exit__\n",
      "    raise asyncio.TimeoutError from None\n",
      "TimeoutError\n"
     ]
    }
   ],
   "source": [
    "def create_prompt(theme):\n",
    "    return (f\"Create a logical arrangement puzzle. \"\n",
    "            f\"Choose a unique {theme} and define a set of objects related to it. \"\n",
    "            f\"Write statements that describe their order or relationships, ensuring logical consistency. \" \n",
    "            f\"Formulate a question that asks for the correct order or relationship, and provide multiple-choice answers. \"\n",
    "            f\"Ensure the puzzle is clear, solvable, and has only one correct answer. \"\n",
    "            f\"For example, 'The following statements each describe a set of five objects arranged in a fixed order. The statements are logically consistent.\\n- In an antique car show, there are five vehicles: a truck, a station wagon, a motorcyle, a convertible, and a hatchback.\\n- The convertible is newer than the truck.\\n- The station wagon is newer than the hatchback.\\n- The convertible is older than the hatchback.\\n- The station wagon is the second-newest.\\n\\nQ: Given the above statements, which of the following is correct?\\nOptions:\\n(A) The truck is the third-newest.\\n(B) The station wagon is the third-newest.\\n(C) The motorcyle is the third-newest.\\n(D) The convertible is the third-newest.\\n(E) The hatchback is the third-newest.'\")\n",
    "\n",
    "\n",
    "def create_system_prompt():\n",
    "    return (f\"Generate a variety of prompts that require the construction of logical puzzles. \"\n",
    "            f\"These prompts should cover a diverse range of themes and challenge the user to create puzzles \"\n",
    "            f\"that are unique and engaging. Each puzzle should include a set of objects, logically consistent statements about their arrangement, \"\n",
    "            f\"and a question that leads to a single correct answer. The aim is to test logical thinking and problem-solving skills.\"\n",
    "            f\"Your response should be JSON in the shape of {{}} with the following structure: \"\n",
    "            f'\"prompt\": \"<theme description>\\\\n- <statement 1>\\\\n- <statement 2>\\\\n...\\\\n\\\\nQ: <question> '\n",
    "            f'\\\\nOptions:\\\\n(A) <option A>\\\\n(B) <option B>\\\\n(C) <option C>\\\\n(D) <option D>\\\\n(E) <option E>\", '\n",
    "            f'... for each puzzle. '\n",
    "            f'Include a unique theme, followed by a series of logically consistent statements about the arrangement of objects related to the theme. '\n",
    "            f'After the statements, present a clear question with multiple choice answers. '\n",
    "            f'Each part should be separated by newline characters (`\\\\n`) for clarity. '\n",
    "            f'The fields \"why_prompt_contains_instruction_keyword\" and \"why_options_choice\" must be consistent with the example provided. '\n",
    "            f'Regularly review your output against this template to ensure correct formatting and maintain the integrity of the puzzles.')\n",
    "\n",
    "async def call_openai_api(prompt, system_prompt, model, max_tokens):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(API_ENDPOINT, headers=headers, json=payload) as response:\n",
    "            if response.status != 200:\n",
    "                print(f\"Error in API call: {response.status}\")\n",
    "                return None\n",
    "            return await response.json()\n",
    "\n",
    "async def generate_data(themes, output_file, model=\"gpt-3.5-turbo-1106\", max_tokens=3800):\n",
    "    theme = random.choice(themes)\n",
    "\n",
    "    prompt = create_prompt(theme)\n",
    "    system_prompt = create_system_prompt()\n",
    "\n",
    "    response = await call_openai_api(prompt, system_prompt, model, max_tokens)\n",
    "    if response and 'choices' in response and len(response['choices']) > 0:\n",
    "        content = response['choices'][0]['message']['content']\n",
    "        try:\n",
    "            # Try to directly parse the content as JSON\n",
    "            parsed_content = json.loads(content)\n",
    "        except json.JSONDecodeError:\n",
    "            # If direct parsing fails, try extracting JSON from code block\n",
    "            try:\n",
    "                json_part = re.search(r'```json\\n(\\{.*\\})\\n```', content, re.DOTALL)\n",
    "                if json_part:\n",
    "                    parsed_content = json.loads(json_part.group(1))\n",
    "                else:\n",
    "                    print(f\"Unable to extract JSON from response: {content}\")\n",
    "                    return\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON response: {e}\")\n",
    "                return\n",
    "\n",
    "        with open(output_file, 'a') as f:\n",
    "            json_string = json.dumps(parsed_content, indent=2)\n",
    "            f.write(json_string + '\\n')\n",
    "        print(f\"Data generation complete. Saved to '{output_file}'.\")\n",
    "    else:\n",
    "        print(f\"Invalid response format or empty 'choices' in response.\")\n",
    "\n",
    "\n",
    "\n",
    "themes = read_jsonl(r'C:\\Users\\eyliw\\code\\finetune\\themes.jsonl', \"theme\")\n",
    "\n",
    "random.shuffle(themes)\n",
    "\n",
    "async def main():\n",
    "    output_file_path = 'logical_puzzle.json'\n",
    "    number_of_prompts_to_generate = 20\n",
    "\n",
    "    tasks = [generate_data(themes, output_file_path) for _ in range(number_of_prompts_to_generate)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    if loop.is_running():\n",
    "        loop.create_task(main())\n",
    "    else:\n",
    "        asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical Puzzle 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON response: Expecting property name enclosed in double quotes: line 3 column 1 (char 415)\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Error parsing JSON response: Expecting ':' delimiter: line 4 column 1 (char 373)\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Data generation complete. Saved to 'logical_puzzle.json'.\n",
      "Error parsing JSON response: Expecting ':' delimiter: line 8 column 51 (char 473)\n"
     ]
    }
   ],
   "source": [
    "def create_prompt(scenario, attribute):\n",
    "    return (f\"Create a logical arrangement puzzle based on the scenario '{scenario}' and attribute '{attribute}'. \"\n",
    "            f\"Formulate statements and a question that asks for the correct order or relationship of entities, \"\n",
    "            f\"ensuring the puzzle is clear, solvable, and has only one correct answer.\"\n",
    "            f\"For example: 'To get into class, the headmistress of the boarding school requires the girls to line up in ascending order of height. Alphonsine is taller than Marie, but shorter than Camille. Madeleine is taller than Suzanne and Camille. Marie is taller than Suzanne, but shorter than Madeleine. \\nIn what order will the girls be arranged?'\")\n",
    "\n",
    "\n",
    "def create_system_prompt():\n",
    "    return (f\"Each puzzle must involve a set of entities, logically consistent statements about their arrangement, \"\n",
    "            f\"and a question that leads to a single correct answer. \"\n",
    "            f\"The aim is to test logical thinking and problem-solving skills. \"\n",
    "            f\"Your response should be JSON in the shape of {{}} with the following structure: \"\n",
    "            f'\"prompt\": \"<scenario description>\\\\n- <statement 1>\\\\n- <statement 2>\\\\n...\\\\n\\\\nQ: <question> '\n",
    "            f'\\\\nA) <option A>\\\\nB) <option B>\\\\nC) <option C>\\\\nD) <option D>\\\\nE) <option E>\", '\n",
    "            f'... for each puzzle. '\n",
    "            f'Include a scenario description, followed by a series of logically consistent statements about the arrangement of objects or entities. '\n",
    "            f'After the statements, present a clear question with multiple choice answers. '\n",
    "            f'Each part should be separated by newline characters (`\\\\n`) for clarity. '\n",
    "            f'Ensure each puzzle is unique and tests logical thinking and problem-solving skills.')\n",
    "\n",
    "async def call_openai_api(prompt, system_prompt, model, max_tokens):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(API_ENDPOINT, headers=headers, json=payload) as response:\n",
    "            if response.status != 200:\n",
    "                print(f\"Error in API call: {response.status}\")\n",
    "                return None\n",
    "            return await response.json()\n",
    "\n",
    "async def generate_data(scenarios, attributes, output_file, model=\"gpt-3.5-turbo-1106\", max_tokens=3800):\n",
    "    scenario = random.choice(scenarios)\n",
    "    attribute = random.choice(attributes)\n",
    "\n",
    "    prompt = create_prompt(scenario, attribute)\n",
    "    system_prompt = create_system_prompt()\n",
    "\n",
    "    response = await call_openai_api(prompt, system_prompt, model, max_tokens)\n",
    "    if response and 'choices' in response and len(response['choices']) > 0:\n",
    "        content = response['choices'][0]['message']['content']\n",
    "        try:\n",
    "            # Try to directly parse the content as JSON\n",
    "            parsed_content = json.loads(content)\n",
    "        except json.JSONDecodeError:\n",
    "            # If direct parsing fails, try extracting JSON from code block\n",
    "            try:\n",
    "                json_part = re.search(r'```json\\n(\\{.*\\})\\n```', content, re.DOTALL)\n",
    "                if json_part:\n",
    "                    parsed_content = json.loads(json_part.group(1))\n",
    "                else:\n",
    "                    print(f\"Unable to extract JSON from response: {content}\")\n",
    "                    return\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON response: {e}\")\n",
    "                return\n",
    "\n",
    "        with open(output_file, 'a') as f:\n",
    "            json_string = json.dumps(parsed_content, indent=2)\n",
    "            f.write(json_string + '\\n')\n",
    "        print(f\"Data generation complete. Saved to '{output_file}'.\")\n",
    "    else:\n",
    "        print(f\"Invalid response format or empty 'choices' in response.\")\n",
    "\n",
    "# Paths and data loading\n",
    "attributes = read_jsonl(r'C:\\Users\\eyliw\\code\\finetune\\attributes.jsonl', \"attribute\")\n",
    "scenarios = read_jsonl(r'C:\\Users\\eyliw\\code\\finetune\\scenarios.jsonl', \"scenario\")\n",
    "themes = read_jsonl(r'C:\\Users\\eyliw\\code\\finetune\\themes.jsonl', \"theme\")\n",
    "output_file_path = 'logical_puzzle.json'\n",
    "\n",
    "# Shuffle lists to add more randomness\n",
    "random.shuffle(attributes)\n",
    "random.shuffle(scenarios)\n",
    "random.shuffle(themes)\n",
    "\n",
    "async def main():\n",
    "    output_file_path = 'logical_puzzle.json'\n",
    "    number_of_prompts_to_generate = 10\n",
    "\n",
    "    tasks = [generate_data(scenarios, attributes, output_file_path) for _ in range(number_of_prompts_to_generate)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    if loop.is_running():\n",
    "        loop.create_task(main())\n",
    "    else:\n",
    "        asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Puzzle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generation complete. Saved to 'P2.json'.\n",
      "Data generation complete. Saved to 'P2.json'.\n",
      "Data generation complete. Saved to 'P2.json'.\n",
      "Error parsing JSON response: Extra data: line 6 column 2 (char 692)\n",
      "Unable to extract JSON from response: {\n",
      "  \"input\": \"Bryan and Maria baked 72 cakes. Bryan baked 8 more cakes than Maria. How many cakes did each bake?\",\n",
      "  \"output\": \"Bryan: 40 cakes, Maria: 32 cakes\",\n",
      "  \"justification\": \"Bryan baked 8 more cakes than Maria, so if we let Maria's number of cakes be x, then Bryan's number of cakes would be x + 8. The total number of cakes they baked is 72, so x + (x + 8) = 72. Solving for x gives x = 32, so Maria baked 32 cakes and Bryan baked 40 cakes.\",\n",
      "  \"thinking_process\": \"Let's set up the equation: x + (x + 8) = 72, where x is the number of cakes Maria baked and (x + 8) is the number of cakes Bryan baked. Solve for x to find the number of cakes each of them baked.\"\n",
      "},\n",
      "{\n",
      "  \"input\": \"Lucas and Sofia sold 140 concert tickets. Lucas sold 10 more tickets than Sofia. How many tickets did each sell?\",\n",
      "  \"output\": \"Lucas: 75 tickets, Sofia: 65 tickets\",\n",
      "  \"justification\": \"Lucas sold 10 more tickets than Sofia, so if we let Sofia's number of tickets be x, then Lucas's number of tickets would be x + 10. The total number of tickets they sold is 140, so x + (x + 10) = 140. Solving for x gives x = 65, so Sofia sold 65 tickets and Lucas sold 75 tickets.\",\n",
      "  \"thinking_process\": \"Let's set up the equation: x + (x + 10) = 140, where x is the number of tickets Sofia sold and (x + 10) is the number of tickets Lucas sold. Solve for x to find the number of tickets each of them sold.\"\n",
      "},\n",
      "{\n",
      "  \"input\": \"Ethan and Olivia found 96 seashells. Ethan found 12 more seashells than Olivia. How many seashells did each find?\",\n",
      "  \"output\": \"Ethan: 54 seashells, Olivia: 42 seashells\",\n",
      "  \"justification\": \"Ethan found 12 more seashells than Olivia, so if we let Olivia's number of seashells be x, then Ethan's number of seashells would be x + 12. The total number of seashells they found is 96, so x + (x + 12) = 96. Solving for x gives x = 42, so Olivia found 42 seashells and Ethan found 54 seashells.\",\n",
      "  \"thinking_process\": \"Let's set up the equation: x + (x + 12) = 96, where x is the number of seashells Olivia found and (x + 12) is the number of seashells Ethan found. Solve for x to find the number of seashells each of them found.\"\n",
      "},\n",
      "{\n",
      "  \"input\": \"Isaac and Emma solved 110 math problems. Isaac solved 15 more problems than Emma. How many problems did each solve?\",\n",
      "  \"output\": \"Isaac: 62 problems, Emma: 48 problems\",\n",
      "  \"justification\": \"Isaac solved 15 more problems than Emma, so if we let Emma's number of problems be x, then Isaac's number of problems would be x + 15. The total number of problems they solved is 110, so x + (x + 15) = 110. Solving for x gives x = 48, so Emma solved 48 problems and Isaac solved 62 problems.\",\n",
      "  \"thinking_process\": \"Let's set up the equation: x + (x + 15) = 110, where x is the number of problems Emma solved and (x + 15) is the number of problems Isaac solved. Solve for x to find the number of problems each of them solved.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-36' coro=<main() done, defined at C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\2902887193.py:87> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\2902887193.py\", line 92, in main\n",
      "    await asyncio.gather(*tasks)\n",
      "  File \"C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\2902887193.py\", line 50, in generate_data\n",
      "    response = await call_openai_api(prompt, system_prompt, model, max_tokens)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\2902887193.py\", line 37, in call_openai_api\n",
      "    async with session.post(API_ENDPOINT, headers=headers, json=payload) as response:\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 894, in start\n",
      "    with self._timer:\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\helpers.py\", line 721, in __exit__\n",
      "    raise asyncio.TimeoutError from None\n",
      "TimeoutError\n"
     ]
    }
   ],
   "source": [
    "def create_prompt():\n",
    "    return (f\"example : 'Germaine and Raymonde picked 90 potatoes. Germaine picked 14 less than Raymonde. How many did they each pick?'\"\n",
    "            f\"Please create a series of math complexe puzzles similar to the Germaine and Raymonde potato picking puzzle. \"\n",
    "            f\"Each puzzle should involve multiples characters engaging in an activity where they collectively achieve a quantifiable result. \"\n",
    "            f\"The relationship between their individual contributions should be similar to the original puzzle. \"\n",
    "            f\"Ensure the puzzle is clear, solvable, and has only one correct answer. \"\n",
    "            f\"Vary the characters, activities, and numerical values for each puzzle. I'd like a large number of these puzzles, each unique in its scenario and numbers.\")\n",
    "\n",
    "def create_system_prompt():\n",
    "    return (f'Your response should be JSON in the shape of {{}} with the following structure: '\n",
    "            f'\"input\": \"<puzzle description>\", \"output\": \"<puzzle solution>\", '\n",
    "            f'\"justification\": \"<explanation of solution>\", \"thinking_process\": \"<detailed thought process>\", '\n",
    "            f'... for each puzzle. '\n",
    "            f'The \"input\" should contain the text of the math puzzle, describing a scenario with two characters, their activity, and the numerical relationship of their contributions. '\n",
    "            f'The \"output\" should hold the correct numerical answer. '\n",
    "            f'The \"justification\" should explain the reasoning or method used to arrive at the solution. '\n",
    "            f'The \"thinking_process\" should detail the step-by-step thought process behind solving the puzzle, including identifying variables, setting up equations, and the logical reasoning used.')\n",
    "\n",
    "async def call_openai_api(prompt, system_prompt, model, max_tokens):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "\n",
    "    async with ClientSession() as session:\n",
    "        async with session.post(API_ENDPOINT, headers=headers, json=payload) as response:\n",
    "            if response.status != 200:\n",
    "                print(f\"Error in API call: {response.status}\")\n",
    "                return None\n",
    "            return await response.json()\n",
    "\n",
    "async def generate_data(output_file, model=\"gpt-3.5-turbo-1106\", max_tokens=3800):\n",
    "    prompt = create_prompt()\n",
    "    system_prompt = create_system_prompt()\n",
    "\n",
    "    response = await call_openai_api(prompt, system_prompt, model, max_tokens)\n",
    "    if response and 'choices' in response and len(response['choices']) > 0:\n",
    "        content = response['choices'][0]['message']['content']\n",
    "        try:\n",
    "            # Try to directly parse the content as JSON\n",
    "            parsed_content = json.loads(content)\n",
    "        except json.JSONDecodeError:\n",
    "            # If direct parsing fails, try extracting JSON from code block\n",
    "            try:\n",
    "                json_part = re.search(r'```json\\n(\\{.*\\})\\n```', content, re.DOTALL)\n",
    "                if json_part:\n",
    "                    parsed_content = json.loads(json_part.group(1))\n",
    "                else:\n",
    "                    print(f\"Unable to extract JSON from response: {content}\")\n",
    "                    return\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON response: {e}\")\n",
    "                return\n",
    "\n",
    "        with open(output_file, 'a') as f:\n",
    "            json_string = json.dumps(parsed_content, indent=2)\n",
    "            f.write(json_string + '\\n')\n",
    "        print(f\"Data generation complete. Saved to '{output_file}'.\")\n",
    "    else:\n",
    "        print(f\"Invalid response format or empty 'choices' in response.\")\n",
    "\n",
    "async def main():\n",
    "    output_file_path = 'P2.json'\n",
    "    number_of_prompts_to_generate = 5\n",
    "\n",
    "    tasks = [generate_data(output_file_path) for _ in range(number_of_prompts_to_generate)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    if loop.is_running():\n",
    "        loop.create_task(main())\n",
    "    else:\n",
    "        asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generation complete. Saved to 'P2.json'.\n",
      "Data generation complete. Saved to 'P2.json'.\n",
      "Unable to extract JSON from response: {\n",
      "  \"input\": \"Alice, Bob, and Claire are friends and passionate coffee drinkers. They each start with a different type of coffee: Alice has Espresso, Bob has Latte, and Claire has Cappuccino. They decide to trade their coffees in the following sequence: Alice and Bob swap coffees, then Bob and Claire swap coffees, and finally Alice and Claire swap coffees. At the end of the trading sequence, who has the Espresso?\",\n",
      "  \"output\": \"Claire\",\n",
      "  \"justification\": \"At the start, Alice has Espresso, Bob has Latte, and Claire has Cappuccino. After the sequence of trades, Alice gives her Espresso to Bob and receives Claire's Cappuccino. Then Bob gives the Espresso to Claire and receives her Cappuccino. Finally, Alice receives the Cappuccino from Bob, while Claire ends up with the Espresso.\",\n",
      "  \"thinking_process\": \"At the beginning, the initial ownership of the coffees is as follows: Alice (Espresso), Bob (Latte), and Claire (Cappuccino). As the trades progress, we track the exchange of coffees and update the ownership accordingly. By following the sequence of trades and updating the owner of each coffee, we can determine that Claire ends up with the Espresso at the end.\" \n",
      "}\n",
      "\n",
      "{\n",
      "  \"input\": \"David, Emily, and Frank are colleagues who are collectors of different types of stamps. David has rare British stamps, Emily has vintage American stamps, and Frank has exotic African stamps. They decide to trade their stamp collections in the following sequence: David and Emily swap stamps, then Emily and Frank swap stamps, and finally David and Frank swap stamps. At the end of the trading sequence, who has the vintage American stamps?\",\n",
      "  \"output\": \"Frank\",\n",
      "  \"justification\": \"At the start, David has rare British stamps, Emily has vintage American stamps, and Frank has exotic African stamps. After the sequence of trades, David gives his British stamps to Emily and receives Frank's exotic African stamps. Then Emily gives the American stamps to Frank and receives his exotic African stamps. Finally, David receives the exotic African stamps from Frank, while Frank ends up with the vintage American stamps.\",\n",
      "  \"thinking_process\": \"At the beginning, the initial ownership of the stamp collections is as follows: David (British), Emily (American), and Frank (African). As the trades progress, we track the exchange of stamp collections and update the ownership accordingly. By following the sequence of trades and updating the owner of each stamp collection, we can determine that Frank ends up with the vintage American stamps at the end.\" \n",
      "}\n",
      "\n",
      "{\n",
      "  \"input\": \"Grace, Henry, and Isabelle are travelers who collect unique artifacts from different countries. Grace has an ancient Egyptian artifact, Henry has a Roman relic, and Isabelle has a Mayan artifact. They decide to trade their artifacts in the following sequence: Grace and Henry swap artifacts, then Henry and Isabelle swap artifacts, and finally Grace and Isabelle swap artifacts. At the end of the trading sequence, who has the ancient Egyptian artifact?\",\n",
      "  \"output\": \"Henry\",\n",
      "  \"justification\": \"At the start, Grace has an ancient Egyptian artifact, Henry has a Roman relic, and Isabelle has a Mayan artifact. After the sequence of trades, Grace gives her Egyptian artifact to Henry and receives Isabelle's Mayan artifact. Then Henry gives the Egyptian artifact to Isabelle and receives her Mayan artifact. Finally, Grace receives the Mayan artifact from Isabelle, while Henry ends up with the ancient Egyptian artifact.\",\n",
      "  \"thinking_process\": \"At the beginning, the initial ownership of the artifacts is as follows: Grace (Egyptian), Henry (Roman), and Isabelle (Mayan). As the trades progress, we track the exchange of artifacts and update the ownership accordingly. By following the sequence of trades and updating the owner of each artifact, we can determine that Henry ends up with the ancient Egyptian artifact at the end.\" \n",
      "}\n",
      "Data generation complete. Saved to 'P2.json'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-221' coro=<main() done, defined at C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\4109212896.py:74> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\4109212896.py\", line 79, in main\n",
      "    await asyncio.gather(*tasks)\n",
      "  File \"C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\4109212896.py\", line 48, in generate_data\n",
      "    response = await call_openai_api(prompt, system_prompt, model, max_tokens)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\4109212896.py\", line 38, in call_openai_api\n",
      "    async with session.post(API_ENDPOINT, headers=headers, json=payload) as response:\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 894, in start\n",
      "    with self._timer:\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\helpers.py\", line 721, in __exit__\n",
      "    raise asyncio.TimeoutError from None\n",
      "TimeoutError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-237' coro=<main() done, defined at C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\4109212896.py:74> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\4109212896.py\", line 79, in main\n",
      "    await asyncio.gather(*tasks)\n",
      "  File \"C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\4109212896.py\", line 48, in generate_data\n",
      "    response = await call_openai_api(prompt, system_prompt, model, max_tokens)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\eyliw\\AppData\\Local\\Temp\\ipykernel_2172\\4109212896.py\", line 38, in call_openai_api\n",
      "    async with session.post(API_ENDPOINT, headers=headers, json=payload) as response:\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 894, in start\n",
      "    with self._timer:\n",
      "  File \"c:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\aiohttp\\helpers.py\", line 721, in __exit__\n",
      "    raise asyncio.TimeoutError from None\n",
      "TimeoutError\n"
     ]
    }
   ],
   "source": [
    "def create_prompt():\n",
    "    return (f\"Example: 'Alice, Bob, and Claire are friends and avid readers who occasionally trade books. \"\n",
    "            f\"At the start of the semester, they each buy one new book: Alice gets The Great Gatsby, \"\n",
    "            f\"Bob gets Ulysses, and Claire gets Moby Dick. As the semester proceeds, they start trading around the new books. \"\n",
    "            f\"First, Alice and Claire swap books. Then, Bob and Claire swap books. Finally, Alice and Claire swap books. \"\n",
    "            f\"At the end of the semester, Alice has\\nOptions:\\n(A) The Great Gatsby.\\n(B) Ulysses.\\n(C) Moby Dick.' \"\n",
    "            f\"Please create a series of puzzles where characters trade or swap items in a sequence. \"\n",
    "            f\"Each puzzle should involve multiple characters and items, with a series of trades leading to a final question about the ownership or position of a specific item. \"\n",
    "            f\"Ensure the puzzle is clear, solvable, and has only one correct answer. \"\n",
    "            f\"Vary the characters, items, and trading sequences for each puzzle. I'd like a large number of these puzzles, each unique in its scenario.\")\n",
    "\n",
    "def create_system_prompt():\n",
    "    return (f'Your response should be JSON in the shape of {{}} with the following structure: '\n",
    "            f'\"input\": \"<puzzle description>\", \"output\": \"<puzzle solution>\", '\n",
    "            f'\"justification\": \"<explanation of solution>\", \"thinking_process\": \"<detailed thought process>\", '\n",
    "            f'... for each puzzle. '\n",
    "            f'The \"input\" should contain the text of the puzzle, describing a scenario with multiple characters, their items, and the sequence of trades. '\n",
    "            f'The \"output\" should specify which item a particular character ends up with. '\n",
    "            f'The \"justification\" should explain the logical steps to determine the final ownership of the item. '\n",
    "            f'The \"thinking_process\" should detail the step-by-step thought process behind solving the puzzle, including tracking the trades, and the logical reasoning used.')\n",
    "\n",
    "async def call_openai_api(prompt, system_prompt, model, max_tokens):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "\n",
    "    async with ClientSession() as session:\n",
    "        async with session.post(API_ENDPOINT, headers=headers, json=payload) as response:\n",
    "            if response.status != 200:\n",
    "                print(f\"Error in API call: {response.status}\")\n",
    "                return None\n",
    "            return await response.json()\n",
    "\n",
    "async def generate_data(output_file, model=\"gpt-3.5-turbo-1106\", max_tokens=3800):\n",
    "    prompt = create_prompt()\n",
    "    system_prompt = create_system_prompt()\n",
    "\n",
    "    response = await call_openai_api(prompt, system_prompt, model, max_tokens)\n",
    "    if response and 'choices' in response and len(response['choices']) > 0:\n",
    "        content = response['choices'][0]['message']['content']\n",
    "        try:\n",
    "            # Try to directly parse the content as JSON\n",
    "            parsed_content = json.loads(content)\n",
    "        except json.JSONDecodeError:\n",
    "            # If direct parsing fails, try extracting JSON from code block\n",
    "            try:\n",
    "                json_part = re.search(r'```json\\n(\\{.*\\})\\n```', content, re.DOTALL)\n",
    "                if json_part:\n",
    "                    parsed_content = json.loads(json_part.group(1))\n",
    "                else:\n",
    "                    print(f\"Unable to extract JSON from response: {content}\")\n",
    "                    return\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON response: {e}\")\n",
    "                return\n",
    "\n",
    "        with open(output_file, 'a') as f:\n",
    "            json_string = json.dumps(parsed_content, indent=2)\n",
    "            f.write(json_string + '\\n')\n",
    "        print(f\"Data generation complete. Saved to '{output_file}'.\")\n",
    "    else:\n",
    "        print(f\"Invalid response format or empty 'choices' in response.\")\n",
    "\n",
    "async def main():\n",
    "    output_file_path = 'P2.json'\n",
    "    number_of_prompts_to_generate = 5\n",
    "\n",
    "    tasks = [generate_data(output_file_path) for _ in range(number_of_prompts_to_generate)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    if loop.is_running():\n",
    "        loop.create_task(main())\n",
    "    else:\n",
    "        asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to extract JSON from response: {\n",
      "  \"input\": \"(((8 / -4 / -2)) - ((-6 * -2 / -3))) =\",\n",
      "  \"output\": \"2\",\n",
      "  \"justification\": \"After solving the equation, the output shows up as 2\",\n",
      "  \"thinking_process\": \"First solve the innermost parentheses. Begin by solving the equation within the parentheses, and then doing the operations in order from left to right.\"\n",
      "},\n",
      "{\n",
      "  \"input\": \"((((12 - 3) * 2) / (18 - 6)) + ((6 / 3) * 5)) =\",\n",
      "  \"output\": \"11\",\n",
      "  \"justification\": \"After solving the equation, the output shows up as 11\",\n",
      "  \"thinking_process\": \"First solve the innermost parentheses. Division and multiplication should be resolved before addition and subtraction.\"\n",
      "},\n",
      "{\n",
      "  \"input\": \"(((7 / -10 / -10)) - ((-7 * -2 / -3))) =\",\n",
      "  \"output\": \"-3\",\n",
      "  \"justification\": \"After doing the calculation, the output shows up as -3\",\n",
      "  \"thinking_process\": \"First solve the innermost parentheses. Division should perform before subtraction.\"\n",
      "},\n",
      "{\n",
      "  \"input\": \"((15 / (-2 * -3)) + (25 - (7 * 2))) =\",\n",
      "  \"output\": \"13\",\n",
      "  \"justification\": \"After solving the equation, the output shows up as 13\",\n",
      "  \"thinking_process\": \"First resolve per parenthesis, then the division and multiplication operations, then addition and finally subtraction.\"\n",
      "},\n",
      "{\n",
      "  \"input\": \"((((5 + 3) * 2) + 6) / (9 - 2)) =\",\n",
      "  \"output\": \"4\",\n",
      "  \"justification\": \"After solving the equation, the output shows up as 4\",\n",
      "  \"thinking_process\": \"First solve the innermost parentheses, then apply the operations from left to right.\"\n",
      "}\n",
      "Unable to extract JSON from response: {\n",
      "    \"input\": \"(((4 * 3) / 2) - ((8 / 4) * 5)) =\",\n",
      "    \"output\": \"-4\",\n",
      "    \"justification\": \"According to the order of operations (PEMDAS/BODMAS), we first solve the operations inside parentheses. In the first parentheses set we do '(4*3)/2' which gives '6', and in the second set we do '(8/4)*5' which gives '10'. Finally, we subtract '10' from '6', which gives us '-4'.\",\n",
      "    \"thinking_process\": \"Let's start by solving the operations inside parentheses first. For (4*3)/2, we multiply 4 by 3 to get 12, then we divide 12 by 2 resulting in 6. For (8/4)*5, we divide 8 by 4 to get 2, then we multiply 2 by 5 resulting in 10. Then we subtract 10 from 6 which equals -4.\"\n",
      "},\n",
      "{\n",
      "    \"input\": \"((3 * 5) + 6) / ((1 - 2 / 3) * 9) =\",\n",
      "    \"output\": \"3\",\n",
      "    \"justification\": \"First we calculate inside parentheses resulting into 15+6=21 and 1-(2/3)=1/3, after that we multiply the second result by 9 to get 3. Finally, we divide the first result (21) by 3, giving the final answer of 7.\",\n",
      "    \"thinking_process\": \"Starting with the operations in parentheses, 3*5 gives us 15, plus 6 gives us 21. In the second set, 1 minus (2/3) gives us 1/3, then multiplied by 9 gives us 3. Dividing 21 by 3, we get our solution which is 7.\"\n",
      "},\n",
      "{\n",
      "    \"input\": \"(10 / - (5 - 3)) + (-3 * 5) =\",\n",
      "    \"output\": \"-20\",\n",
      "    \"justification\": \"We begin with the operation inside parentheses: 5-3 gives 2. Then, we go on with the division: 10 divided by -2 gives -5. Afterwards, we multiply -3 by 5 which results in -15. Adding -5 and -15, we reach the final answer of -20.\",\n",
      "    \"thinking_process\": \"Looking at the operations in parentheses, 5 minus 3 equals 2. Then we divide 10 by -2 resulting in -5. Afterwards, -3 times 5 equals -15. Adding the results of these operations, -5 plus -15, we get -20.\"\n",
      "}\n",
      "Unable to extract JSON from response: {\n",
      "  \"input\": \"(((5 * 3 / 2 - 4)) * ((4 + 7 / 2))) =\",\n",
      "  \"output\": \"56.25\",\n",
      "  \"justification\": \"According to the BODMAS rule, the operations within a mathematical expression are performed in the following order: Brackets, Orders (powers and square roots), Division and Multiplication (from left to right), Addition and Subtraction (from left to right). Using this rule, the expression (((5 * 3 / 2 - 4)) * ((4 + 7 / 2))) is solved as follows: ((15 / 2 - 4)) * ((4 + 3.5)) = ((7.5 - 4)) * 7.5 = 26.25 * 7.5 = 196.875, but the correct answer is 56.25\",\n",
      "  \"thinking_process\": \"Firstly, I analyzed the expression using the BODMAS rule which states that operations within brackets are done first followed by orders, division and multiplication and then addition and subtraction. For the first part of the expression (5 * 3 / 2 - 4), I multiplied 5 by 3 to get 15 and divided it by 2 to get 7.5 then subtracted 4 to get 3.5. For the second part of the expression (4 + 7 / 2), I divided 7 by 2 to get 3.5 and added it to 4 to get 7.5. Finally, I multiplied both parts of the expression to get the final result.\"\n",
      "},\n",
      "{\n",
      "  \"input\": \"((6 + 10 / 2) * (5 - 1) / 2) =\",\n",
      "  \"output\": \"16\",\n",
      "  \"justification\": \"The BODMAS rule should be applied to solve this expression. According to this rule, the operations within a mathematical expression are performed in the following order: Brackets, Orders (powers and square roots), Division and Multiplication (from left to right), Addition and Subtraction (from left to right). The expression ((6 + 10 / 2) * (5 - 1) / 2) is solved as follows: ((6 + 5) * 4 / 2) = (11 * 4 / 2) = 44 / 2 = 22. But the correct output is 16.\",\n",
      "  \"thinking_process\": \"I evaluated the expression following the BODMAS rule. I completed operations within the brackets first. For the first bracket (6 + 10 / 2), I carried out the division first, dividing 10 by 2 to get 5 and then adding the result to 6 to get 11. For the second bracket (5 - 1), I subtracted 1 from 5 to get 4. Then, I multiplied the results from the brackets together and divided by 2 to get the final result.\"\n",
      "},\n",
      "{\n",
      "  \"input\": \"(((4 * 2 + 6) / 12) + ((3 * 5 - 2) / 8)) =\",\n",
      "  \"output\": \"1.0625\",\n",
      "  \"justification\": \"We use the BODMAS principle to solve this problem, which means the operations inside brackets are performed first, then multiplication and division, and finally addition and subtraction. For the first bracket (4 * 2 + 6) / 12, we multiply 4 and 2 to get 8, add 6 to get 14 and then divide by 12 to get 1.1666666666666667. For the second bracket (3 * 5 - 2) / 8, we multiply 3 by 5 to get 15, subtract 2 to get 13, then divide by 8 to get 1.625. Adding these two results together gives us 2.7916666666666665, but the correct answer is 1.0625.\",\n",
      "  \"thinking_process\": \"To solve this problem, I started with the first expression in the brackets (4 * 2 + 6) / 12. I multiplied 4 by 2 to get 8, then added 6 to get 14 and divided by 12 to get 1.1666666666666667. Next, I dealt with the second bracket (3 * 5 - 2) / 8. I multiplied 3 by 5 to get 15, subtracted 2 to get 13, and then divided by 8 to get 1.625. Finally, I added the two results together to get the final answer.\"\n",
      "}\n",
      "Data generation complete. Saved to 'P2.json'.\n",
      "Unable to extract JSON from response: {\n",
      "  \"input\": \"(((15 / 3 + 7)) * ((8 * 2 / 4))) =\",\n",
      "  \"output\": \"40\",\n",
      "  \"justification\": \"First, solve the operations within each set of parentheses, starting with the innermost brackets. For the left set, 15 / 3 = 5 and 5 + 7 = 12. For the right set, 8 * 2 = 16, and then 16 / 4 = 4. Finally, multiply the results of the two sets of parentheses to get 12 * 4 = 48.\",\n",
      "  \"thinking_process\": \"My first step was to calculate the expression within the innermost parentheses, which are (15/3+7) and (8*2/4). I performed the division first (because of the order of operations), resulting in (5 + 7) = 12 and (16 / 4) = 4. So our simplified equation now becomes 12 * 4, which equals to 48.\"\n",
      "},\n",
      "{\n",
      "  \"input\": \"(((25 - 10 * 2)) / ((4 + 3 * 2))) =\",\n",
      "  \"output\": \"1\",\n",
      "  \"justification\": \"Within each set of parentheses, perform the multiplication before the subtraction or addition. For the left set, 10 * 2 = 20, and then 25 - 20 = 5. For the right set, 3 * 2 = 6, and then 4 + 6 = 10. Finally, divide the results of the two sets of parentheses to get 5 / 10 = 0.5.\",\n",
      "  \"thinking_process\": \"I first tackled the expression within the innermost brackets, (25 - 10*2) and (4 + 3*2). For the first set, I performed the multiplication operation first because of the order of operations (BIDMAS), leading to (25-20) = 5. For the second set, I again performed the multiplication first giving (4 + 6) = 10. This leaves us with the expression 5 / 10, which simplifies to 0.5.\"\n",
      "},\n",
      "{\n",
      "  \"input\": \"(((1 + 4 * 3)) - ((8 / 2 * 2))) =\",\n",
      "  \"output\": \"7\",\n",
      "  \"justification\": \"Inside each set of parentheses, carry out the multiplication before the addition or division. In the left set, 4 * 3 = 12, then 1 + 12 = 13. In the right set, 8 / 2 = 4, then 4 * 2 = 8. Finally, subtract the results of the two sets of parentheses to get 13 - 8 = 5.\",\n",
      "  \"thinking_process\": \"Initially, I focused on the innermost parentheses, (1 + 4*3) and (8/2*2). In the first set, I performed multiplication before addition due to the order of operations, which gave (1 + 12) = 13. In the second set, I performed division before multiplication which gave (4 * 2) = 8. Finally, I subtracted the two resulting values, giving 13 - 8 = 5.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def create_math_expression():\n",
    "    operators = ['+', '-', '*', '/']\n",
    "    numbers = [str(random.randint(-10, 10)) for _ in range(3)]\n",
    "    inner_expression = f\"({numbers[0]} {random.choice(operators)} {numbers[1]} {random.choice(operators)} {numbers[2]})\"\n",
    "    \n",
    "    numbers = [str(random.randint(-10, 10)) for _ in range(3)]\n",
    "    outer_expression = f\"({numbers[0]} {random.choice(operators)} {numbers[1]} {random.choice(operators)} {numbers[2]})\"\n",
    "    \n",
    "    final_expression = f\"(({inner_expression}) {random.choice(operators)} ({outer_expression})) =\"\n",
    "    return final_expression\n",
    "\n",
    "def create_prompt():\n",
    "    math_puzzle = create_math_expression()\n",
    "    return (f\"example : '{math_puzzle}'\"\n",
    "            f\"Please create a series of complex math puzzles similar to the example. \"\n",
    "            f\"Each puzzle should be a single line arithmetic expression involving a combination of operations (addition, subtraction, multiplication, division) \"\n",
    "            f\"and grouping with parentheses. \"\n",
    "            f\"Ensure the puzzle is clear, solvable, and each has a unique structure.\")\n",
    "\n",
    "\n",
    "async def call_openai_api(prompt, system_prompt, model, max_tokens):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "\n",
    "    async with ClientSession() as session:\n",
    "        async with session.post(API_ENDPOINT, headers=headers, json=payload) as response:\n",
    "            if response.status != 200:\n",
    "                print(f\"Error in API call: {response.status}\")\n",
    "                return None\n",
    "            return await response.json()\n",
    "\n",
    "async def generate_data(output_file, model=\"gpt-3.5-turbo-1106\", max_tokens=3800):\n",
    "    prompt = create_prompt()\n",
    "    system_prompt = create_system_prompt()\n",
    "\n",
    "    response = await call_openai_api(prompt, system_prompt, model, max_tokens)\n",
    "    if response and 'choices' in response and len(response['choices']) > 0:\n",
    "        content = response['choices'][0]['message']['content']\n",
    "        try:\n",
    "            # Try to directly parse the content as JSON\n",
    "            parsed_content = json.loads(content)\n",
    "        except json.JSONDecodeError:\n",
    "            # If direct parsing fails, try extracting JSON from code block\n",
    "            try:\n",
    "                json_part = re.search(r'```json\\n(\\{.*\\})\\n```', content, re.DOTALL)\n",
    "                if json_part:\n",
    "                    parsed_content = json.loads(json_part.group(1))\n",
    "                else:\n",
    "                    print(f\"Unable to extract JSON from response: {content}\")\n",
    "                    return\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON response: {e}\")\n",
    "                return\n",
    "\n",
    "        with open(output_file, 'a') as f:\n",
    "            json_string = json.dumps(parsed_content, indent=2)\n",
    "            f.write(json_string + '\\n')\n",
    "        print(f\"Data generation complete. Saved to '{output_file}'.\")\n",
    "    else:\n",
    "        print(f\"Invalid response format or empty 'choices' in response.\")\n",
    "\n",
    "async def main():\n",
    "    output_file_path = 'P2.json'\n",
    "    number_of_prompts_to_generate = 5\n",
    "\n",
    "    tasks = [generate_data(output_file_path) for _ in range(number_of_prompts_to_generate)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    if loop.is_running():\n",
    "        loop.create_task(main())\n",
    "    else:\n",
    "        asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Q-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generation complete. Saved to 'P2.json'.\n",
      "Error parsing JSON response: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing JSON response: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing JSON response: Expecting value: line 1 column 1 (char 0)\n",
      "Data generation complete. Saved to 'P2.json'.\n",
      "Data generation complete. Saved to 'P2.json'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_prompt(prompt_obj):\n",
    "    return (f'input: {prompt_obj[\"prompt\"]}\\n\\n'\n",
    "            f'Task: Understand the input, identify its direct instruction. '\n",
    "            f'Based on this understanding, use the full input to formulate a response. '\n",
    "            f'This response is your output. '\n",
    "            f'Justify your reasoning and explain the thinking process behind generating the output. '\n",
    "            f'Format your response as JSON with the keys \"input\", \"output\", \"justification\", \"thinking_process\". '\n",
    "            f'Ensure that the response adheres strictly to this structure, without any additional fields.')\n",
    "\n",
    "def create_system_prompt():\n",
    "    return (f'Your task is to analyze and respond to the provided prompt. '\n",
    "            f'The response should be structured as JSON with the following keys: '\n",
    "            f'1. \"input\": <introduction> \\\\n<statemtents> \\\\n<Q:> \\\\n<options>. '\n",
    "            f'2. \"output\": Your direct response to the \"input\", formatted as text. '\n",
    "            f'3. \"justification\": Explain the reasoning behind your response. '\n",
    "            f'4. \"thinking_process\": Detail the thought process that led to the generation of the output. '\n",
    "            f'Ensure that each of these fields is provided and that your response strictly adheres to this structure. '\n",
    "            f'Do not include any additional fields.')\n",
    "\n",
    "async def call_openai_api(prompt, system_prompt):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": MAX_TOKENS\n",
    "    }\n",
    "\n",
    "    async with ClientSession() as session:\n",
    "        async with session.post(API_ENDPOINT, headers=headers, json=payload) as response:\n",
    "            if response.status != 200:\n",
    "                # Implement retry logic with exponential backoff here if needed\n",
    "                return None\n",
    "            return await response.json()\n",
    "\n",
    "async def generate_data_async(prompt_obj, output_file):\n",
    "    prompt = create_prompt(prompt_obj)\n",
    "    system_prompt = create_system_prompt()\n",
    "\n",
    "    response = await call_openai_api(prompt, system_prompt)\n",
    "    if response:\n",
    "        # Check if the response contains the expected keys\n",
    "        if 'choices' in response and len(response['choices']) > 0:\n",
    "            content = response['choices'][0]['message']['content']\n",
    "            try:\n",
    "                # Parse the JSON string into a Python dictionary\n",
    "                parsed_content = json.loads(content)\n",
    "                with open(output_file, 'a') as f:\n",
    "                    # Write the parsed content as a JSON string with proper formatting\n",
    "                    json_string = json.dumps(parsed_content, indent=2)\n",
    "                    f.write(json_string + '\\n')\n",
    "\n",
    "                print(f\"Data generation complete. Saved to '{output_file}'.\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON response: {e}\")\n",
    "        else:\n",
    "            print(f\"Invalid response format: {response}\")\n",
    "\n",
    "async def main():\n",
    "    prompts = process_generated_prompts('logical_puzzle.json')\n",
    "    output_file_path = 'P2.json'\n",
    "    number_of_prompts_to_generate = 6\n",
    "\n",
    "    tasks = [generate_data_async(random.choice(prompts), output_file_path) for _ in range(number_of_prompts_to_generate)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# This checks if there's an existing event loop and uses it instead of creating a new one.\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    if loop.is_running():\n",
    "        # If the loop is already running, just add the main coroutine to the loop.\n",
    "        loop.create_task(main())\n",
    "    else:\n",
    "        # Otherwise, use asyncio.run (for standalone scripts)\n",
    "        asyncio.run(main())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating data from P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to read JSON file and return data\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def create_jsonl(json_data, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        for item in json_data.get('P2', []):  # Safely get 'P2' key\n",
    "            output = item.get('output', '')  # Safely get 'output' key, default to empty string if not found\n",
    "            thinking_process = item.get('thinking_process', '')  # Safely get 'thinking_process'\n",
    "\n",
    "            if thinking_process:\n",
    "                output += \"\\nThinking Process: \" + thinking_process\n",
    "\n",
    "            jsonl_obj = {\n",
    "                \"instruction\": item.get('instruction', ''), \n",
    "                \"input\": item.get('input', ''),  # Safely get 'input'\n",
    "                \"output\": output\n",
    "            }\n",
    "\n",
    "            file.write(json.dumps(jsonl_obj) + '\\n')\n",
    "\n",
    "\n",
    "# Path to the original JSON file and the output JSONL file\n",
    "input_file_name = 'P2.json'\n",
    "output_file_name = 'output.jsonl'\n",
    "\n",
    "# Read data from the JSON file\n",
    "json_data = read_json_file(input_file_name)\n",
    "\n",
    "# Create the JSONL file\n",
    "create_jsonl(json_data, output_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
