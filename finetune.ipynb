{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai tiktoken wandb -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from getpass import getpass\n",
    "\n",
    "from rich.markdown import Markdown\n",
    "import pandas as pd\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential, # for exponential backoff\n",
    ")  \n",
    "import wandb\n",
    "from wandb.integration.openai import autolog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.update({\n",
    "    'OPENAI_API_KEY': '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'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_temperature(temp):\n",
    "  \"Generate text with a given temperature, higher temperature means more randomness\"\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", \n",
    "    messages=\n",
    "    [\n",
    "      {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Hello world\"\n",
    "        }\n",
    "        ],\n",
    "    temperature = temp)\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TEMP: 0, GENERATION: Hello! How can I assist you today?'\n",
      "'TEMP: 0.5, GENERATION: Hello! How can I assist you today?'\n",
      "'TEMP: 1, GENERATION: Hello! How can I assist you today?'\n",
      "'TEMP: 1.5, GENERATION: Hello! How can I assist you today?'\n"
     ]
    }
   ],
   "source": [
    "for temp in [0, 0.5, 1, 1.5]:\n",
    "  pprint(f\"TEMP: {temp}, GENERATION: {generate_with_temperature(temp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation de donn√©es (dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mteilo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\eyliw\\code\\finetune\\wandb\\run-20231115_211530-v8z0rvcy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/teilo/llmapps/runs/v8z0rvcy' target=\"_blank\">wild-river-3</a></strong> to <a href='https://wandb.ai/teilo/llmapps' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/teilo/llmapps' target=\"_blank\">https://wandb.ai/teilo/llmapps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/teilo/llmapps/runs/v8z0rvcy' target=\"_blank\">https://wandb.ai/teilo/llmapps/runs/v8z0rvcy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Edit, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\eyliw\\code\\finetune\\finetune.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eyliw/code/finetune/finetune.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# start logging to W&B\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/eyliw/code/finetune/finetune.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m autolog({\u001b[39m\"\u001b[39;49m\u001b[39mproject\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mllmapps\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mjob_type\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mgeneration\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n",
      "File \u001b[1;32mc:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\wandb\\sdk\\integration_utils\\auto_logging.py:184\u001b[0m, in \u001b[0;36mAutologAPI.__call__\u001b[1;34m(self, init)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, init: AutologInitArgs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Enable autologging.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable(init\u001b[39m=\u001b[39;49minit)\n",
      "File \u001b[1;32mc:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\wandb\\sdk\\integration_utils\\auto_logging.py:221\u001b[0m, in \u001b[0;36mAutologAPI.enable\u001b[1;34m(self, init)\u001b[0m\n\u001b[0;32m    218\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEnabling \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name\u001b[39m}\u001b[39;00m\u001b[39m autologging.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    219\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_init(init\u001b[39m=\u001b[39minit)\n\u001b[1;32m--> 221\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_patch_api\u001b[39m.\u001b[39;49mpatch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run)\n\u001b[0;32m    223\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_telemetry_feature:\n\u001b[0;32m    224\u001b[0m     \u001b[39mwith\u001b[39;00m wb_telemetry\u001b[39m.\u001b[39mcontext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run) \u001b[39mas\u001b[39;00m tel:\n",
      "File \u001b[1;32mc:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\wandb\\sdk\\integration_utils\\auto_logging.py:88\u001b[0m, in \u001b[0;36mPatchAPI.patch\u001b[1;34m(self, run)\u001b[0m\n\u001b[0;32m     86\u001b[0m symbol_parts \u001b[39m=\u001b[39m symbol\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[39m# and get the attribute from the module\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m original \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39;49mreduce(\u001b[39mgetattr\u001b[39;49m, symbol_parts, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_api)\n\u001b[0;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmethod_factory\u001b[39m(original_method: Any):\n\u001b[0;32m     91\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39masync_method\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "File \u001b[1;32mc:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_proxy.py:22\u001b[0m, in \u001b[0;36mLazyProxy.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, attr: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_proxied__(), attr)\n",
      "File \u001b[1;32mc:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_proxy.py:43\u001b[0m, in \u001b[0;36mLazyProxy.__get_proxied__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__get_proxied__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshould_cache:\n\u001b[1;32m---> 43\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load__()\n\u001b[0;32m     45\u001b[0m     proxied \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__proxied\n\u001b[0;32m     46\u001b[0m     \u001b[39mif\u001b[39;00m proxied \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\eyliw\\anaconda3\\Lib\\site-packages\\openai\\lib\\_old_api.py:33\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__load__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m@override\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__load__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[39mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Edit, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# start logging to W&B\n",
    "autolog({\"project\":\"llmapps\", \"job_type\": \"generation\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    return client.chat.completions.create(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "# MODEL_NAME = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"Can you provide me with detailed measurements for the size small in this sportswear brand? I want to make sure the\n",
       "fit is perfect before making a purchase.\"                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\"Can you provide me with detailed measurements for the size small in this sportswear brand? I want to make sure the\n",
       "fit is perfect before making a purchase.\"                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"Can you help me find the right size of running shoes for my feet?\"                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\"Can you help me find the right size of running shoes for my feet?\"                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"Hey there, I recently purchased a new pair of running shoes from your brand, but I've been experiencing discomfort\n",
       "and pain in my feet while wearing them. Is there anything I can do to alleviate this issue or possibly get a       \n",
       "refund/exchange?\"                                                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\"Hey there, I recently purchased a new pair of running shoes from your brand, but I've been experiencing discomfort\n",
       "and pain in my feet while wearing them. Is there anything I can do to alleviate this issue or possibly get a       \n",
       "refund/exchange?\"                                                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"Can you provide me with recommendations for sportswear that offers breathable fabrics and moisture-wicking        \n",
       "properties for intense workouts?\"                                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\"Can you provide me with recommendations for sportswear that offers breathable fabrics and moisture-wicking        \n",
       "properties for intense workouts?\"                                                                                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"I recently purchased a pair of running shoes from your brand, but I'm experiencing discomfort during my runs. Can \n",
       "you provide me with any advice or suggestions to improve the fit and overall comfort of the shoes?\"                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\"I recently purchased a pair of running shoes from your brand, but I'm experiencing discomfort during my runs. Can \n",
       "you provide me with any advice or suggestions to improve the fit and overall comfort of the shoes?\"                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "user_prompt = \"Generate a support question from a sportswear customer\"\n",
    "\n",
    "def generate_and_print(system_prompt, user_prompt, n=5):\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    responses = completion_with_backoff(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        n = n,\n",
    "        )\n",
    "    for response in responses.choices:\n",
    "        generation = response.message.content\n",
    "        display(Markdown(generation))\n",
    "    \n",
    "generate_and_print(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
